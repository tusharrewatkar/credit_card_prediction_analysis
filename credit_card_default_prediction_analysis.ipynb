{
  "cells": [
    {
      "metadata": {
        "_uuid": "4b801e405e34367b0da9007ffc28c0d58cb978b3",
        "id": "R9JSfw1Wa9IQ"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook uses the UCI CreditCardFraud data - the task is to see which variables are the strongest predictors of default, and to make predictions on which customers are likely to default.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e903319f720d0ce75fe0030aaf4785031af9552f",
        "id": "Dlc2h2Gea9IV"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy.stats as stats\n",
        "\n",
        "data = pd.read_csv(\"../input/UCI_Credit_Card.csv\")\n",
        "data.head(10)\n",
        "\n",
        "data.columns"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "89085aa198294a24e7fd22f9aa211fcd01571be3",
        "id": "u2KocRHLa9IY"
      },
      "cell_type": "markdown",
      "source": [
        "**Let's look at the data.** Since our dependent variable is categorical, we can split the distributions by \"default/not-default\" to look at\n",
        "the characteristics of the default/not-default groups"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "dd86062dee149bfde289fa955d31a6954621d42d",
        "id": "HIXG2GiFa9Ib"
      },
      "cell_type": "code",
      "source": [
        "output = 'default.payment.next.month'\n",
        "\n",
        "# Let's do a little EDA\n",
        "cols = [ f for f in data.columns if data.dtypes[ f ] != \"object\"]\n",
        "cols.remove( \"ID\")\n",
        "cols.remove( output )\n",
        "\n",
        "f = pd.melt( data, id_vars=output, value_vars=cols)\n",
        "g = sns.FacetGrid( f, hue=output, col=\"variable\", col_wrap=5, sharex=False, sharey=False )\n",
        "g = g.map( sns.distplot, \"value\", kde=True).add_legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0cc388a6384d969f866c819124e1cb24288163ac",
        "id": "RhSpm5bIa9Id"
      },
      "cell_type": "markdown",
      "source": [
        "**Observations:**\n",
        "*     Defaults have a higher proportion of Lower LIMIT_BAL values\n",
        "*     NonDefaults have a higher proportion of Females (Sex=2)\n",
        "*     NonDefaults have a higher proportion of MoreEducated (EDUCATION=1 or 2)\n",
        "*     NonDefaults have a higher proportion of Singles (MARRIAGE=2)\n",
        "*     NonDefaults have a higher proportion of people 30-40years\n",
        "*     NonDefaults have a MUCH higher proportion of zero or negative PAY_X variables \n",
        "        (this means that being current or ahead of payments is associated with not defaulting in the following month).\n",
        "        **This is a strong relationship as the distribution are more separated - so we expect the PAY_X to be important!**\n",
        "\n",
        "(Clearly we're going to have to transform those dollar amounts in the PAY_AMTX and BILL_AMTX variables.)\n",
        "\n",
        "How significant are these relationships? Given the observed data, is it possible we're imagining relationships when they're not really that strong? "
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "5e9213fb9d9b202c257099c88a4b4514ed4b0b8b",
        "id": "fgV9PmrHa9If"
      },
      "cell_type": "code",
      "source": [
        "def ChiSquaredTestOfIndependence( df, inputVar, Outcome_Category ):\n",
        "    # Useful to have this wrapped in a function\n",
        "    # The ChiSquaredTest of Independence - \n",
        "    # has a null hypothesis: the OutcomeCategory is independent of the inputVar\n",
        "    # So we create a test-statistic which is a measure of the difference between \n",
        "    # \"expected\" i.e. what we WOULD observe if the OutcomeCategory WAS independent of the inputVar\n",
        "    # \"observed\" i.e. what the data actually shows\n",
        "    # the p-value returned is the probability of seeing this test-statistic if the null-hypothesis is true\n",
        "    Outcome_Category_Table = df.groupby( Outcome_Category )[ Outcome_Category ].count().values\n",
        "    Outcome_Category_Ratios = Outcome_Category_Table / sum( Outcome_Category_Table )\n",
        "    possibleVals = df[inputVar].unique()\n",
        "    observed = []\n",
        "    expected = []\n",
        "    for possible in possibleVals:\n",
        "        countsInCategories = df[ df[ inputVar ] == possible ].groupby( Outcome_Category )[Outcome_Category].count().values\n",
        "        if( len(countsInCategories) != len( Outcome_Category_Ratios ) ):\n",
        "            print(\"Error! The class \" + str( possible) +\" of \\'\" + inputVar + \"\\' does not contain all values of \\'\" + Outcome_Category + \"\\'\" )\n",
        "            return\n",
        "        elif( min(countsInCategories) < 5 ):\n",
        "            print(\"Chi Squared Test needs at least 5 observations in each cell!\")\n",
        "            print( inputVar + \"=\" + str(possible) + \" has insufficient data\")\n",
        "            print( countsInCategories )\n",
        "            return\n",
        "        else:\n",
        "            observed.append( countsInCategories )   \n",
        "            expected.append( Outcome_Category_Ratios * len( df[df[ inputVar ] == possible ]))\n",
        "    observed = np.array( observed )\n",
        "    expected = np.array( expected )\n",
        "    chi_squared_stat = ((observed - expected)**2 / expected).sum().sum()\n",
        "    degOfF = (observed.shape[0] - 1 ) *(observed.shape[1] - 1 ) \n",
        "    #crit = stats.chi2.ppf(q = 0.95,df = degOfF) \n",
        "    p_value = 1 - stats.chi2.cdf(x=chi_squared_stat, df=degOfF)\n",
        "    print(\"Calculated test-statistic is %.2f\" % chi_squared_stat )\n",
        "    print(\"If \" + Outcome_Category + \" is indep of \" + inputVar + \", this has prob %.2e of occurring\" % p_value )\n",
        "    #t_stat, p_val, doF, expArray = stats.chi2_contingency(observed= observed, correction=False)\n",
        "    #print(\"Using built-in stats test: outputs\")\n",
        "    #print(\"test-statistic=%.2f, p-value=%.2f, degsOfFreedom=%d\" % ( t_stat, p_val, doF ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "55fa4f89de8a4c86ce902b816c24e91a93bffb17",
        "id": "SMuzWwq1a9Ii"
      },
      "cell_type": "code",
      "source": [
        "ChiSquaredTestOfIndependence( data, \"SEX\", output )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9fb55156dab45957395606a40616d565cd85cb91",
        "id": "hTdmGX6wa9Ik"
      },
      "cell_type": "code",
      "source": [
        "# Ok. So \"default\" is not independent of \"SEX\".\n",
        "ChiSquaredTestOfIndependence( data, \"EDUCATION\", output )   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e822fb1db7625b6bcaacf9ce19b87523a27e4e29",
        "id": "R4uQ_11ha9Il"
      },
      "cell_type": "markdown",
      "source": [
        "There aren't enough values in the Education class =0. We'll probably find the same for the non-typical-looking values Education = 4, 5, 6. How many of each do we have?"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "4c450a7c4cd9f779a9fa5be316359a404d536467",
        "id": "Do4rFpoZa9In"
      },
      "cell_type": "code",
      "source": [
        "print(\"We have %d with EDUCATION=0\" % len(data.loc[ data[\"EDUCATION\"]==0]))\n",
        "print(\"We have %d with EDUCATION=4\" % len(data.loc[ data[\"EDUCATION\"]==4]))\n",
        "print(\"We have %d with EDUCATION=5\" % len(data.loc[ data[\"EDUCATION\"]==5]))\n",
        "print(\"We have %d with EDUCATION=6\" % len(data.loc[ data[\"EDUCATION\"]==6]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "aa6274293def1ba1fb032acbed0158f26527ecba",
        "id": "S6AVFopZa9Ip"
      },
      "cell_type": "code",
      "source": [
        "# Since we have 30k samples, let's just put these non-typical Education instances all into the EDUCATION=4 class and continue \n",
        "data[\"EDUCATION_Corr\"] = data[\"EDUCATION\"].apply( lambda x: x if ((x>0) and (x<4)) else 4 )\n",
        "ChiSquaredTestOfIndependence( data, \"EDUCATION_Corr\", output ) \n",
        "cols.remove(\"EDUCATION\")\n",
        "cols.append(\"EDUCATION_Corr\")\n",
        "\n",
        "ChiSquaredTestOfIndependence( data, \"MARRIAGE\", output ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "017cb41b1d657377b4cd44cd596d0011fc111867",
        "id": "M-FCSTx8a9Ir"
      },
      "cell_type": "markdown",
      "source": [
        "Ok. So default is not independent of EDUCATION_Corr nor independent of MARRIAGE.\n",
        "\n",
        "I find it useful to separate the variables into \"quantitative\" vs \"qualitative\" and also to keep track of those that I've transformed (instead of overwriting them)."
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "0cfe1439c1ee24237c1471751715384c31756e3a",
        "id": "R34mFqCya9Is"
      },
      "cell_type": "code",
      "source": [
        "# The quantitative vars:\n",
        "quant = [\"LIMIT_BAL\", \"AGE\"]\n",
        "\n",
        "# The qualitative but \"Encoded\" variables (ie most of them)\n",
        "qual_Enc = cols\n",
        "qual_Enc.remove(\"LIMIT_BAL\")\n",
        "qual_Enc.remove(\"AGE\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "7d3a3204ed1054952e6d100d6061b087c5c1277f",
        "id": "TRykoQmka9Iu"
      },
      "cell_type": "markdown",
      "source": [
        "And the PAY_ variables? We can see those are important, but we'll transform the BILL_AMT and PAY_AMT variables from NT Dollars to Log(NT Dollars)"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "354a9a3b9927c00ba495afc697b89b19d1d4c984",
        "id": "krKIvfZDa9Iv"
      },
      "cell_type": "code",
      "source": [
        "logged = []\n",
        "for ii in range(1,7):\n",
        "    qual_Enc.remove(\"PAY_AMT\" + str( ii ))\n",
        "    data[ \"log_PAY_AMT\" + str( ii )]  = data[\"PAY_AMT\"  + str( ii )].apply( lambda x: np.log1p(x) if (x>0) else 0 )\n",
        "    logged.append(\"log_PAY_AMT\" + str( ii ) )\n",
        "\n",
        "for ii in range(1,7):\n",
        "    qual_Enc.remove(\"BILL_AMT\" + str( ii ))\n",
        "    data[ \"log_BILL_AMT\" + str( ii )] = data[\"BILL_AMT\" + str( ii )].apply( lambda x: np.log1p(x) if (x>0) else 0 )\n",
        "    logged.append(\"log_BILL_AMT\" + str( ii ) )\n",
        "\n",
        "f = pd.melt( data, id_vars=output, value_vars=logged)\n",
        "g = sns.FacetGrid( f, hue=output, col=\"variable\", col_wrap=3, sharex=False, sharey=False )\n",
        "g = g.map( sns.distplot, \"value\", kde=True).add_legend()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "81b7b3bb8cdbf0563c8f3b7abcd760a3b7e28d31",
        "id": "l3BVMAcLa9Ix"
      },
      "cell_type": "markdown",
      "source": [
        "It *looks like* higher Log PAY_AMT is associated with *slightly less default*.\n",
        "\n",
        "So now we have quant variables, qual_Enc variables and logged variables. Let's check correlations with the output variable:"
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "e169b6a355a4129a80b584caf2505b312825a803",
        "id": "H1sZdrALa9Iy"
      },
      "cell_type": "code",
      "source": [
        "features = quant + qual_Enc + logged + [output]\n",
        "corr = data[features].corr()\n",
        "plt.subplots(figsize=(30,10))\n",
        "sns.heatmap( corr, square=True, annot=True, fmt=\".1f\" )  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "383519bbf164972d1d1fdedeb5a202f57ea72034",
        "id": "HFvevNAla9I0"
      },
      "cell_type": "markdown",
      "source": [
        "So it looks like the PAY_0, PAY_X variables are the strongest predictors of default, followed by the LIMIT_BAL and Log_PAY_AMT variables.\n",
        "\n",
        "To make predictions about whether a customer is likely to default  - we'll train a number of different classifiers and see how well they perform. As usual, we start by splitting the data into train/test sets and rescaling."
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "d47eafab102528417eeb89ace61f59cda6ac2f16",
        "id": "sGet50D6a9I1"
      },
      "cell_type": "code",
      "source": [
        "features = quant + qual_Enc + logged   \n",
        "X = data[features].values    \n",
        "y = data[ output ].values\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.2)\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scX = StandardScaler()\n",
        "X_train = scX.fit_transform( X_train )\n",
        "X_test = scX.transform( X_test )\n",
        "\n",
        "# We'll need some metrics to evaluate our models\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "4994c6741d6fa4e3df9eb327517b10126aee5e40",
        "id": "PakKIGyUa9I2"
      },
      "cell_type": "markdown",
      "source": [
        "We don't expect the data to be linearly separable - so we'll start with the RandomForest classifier and kernel-SVM "
      ]
    },
    {
      "metadata": {
        "collapsed": true,
        "trusted": true,
        "_uuid": "05e84d6062b2456611c183bb3787c7a70ecec1b5",
        "id": "0JOzN2rRa9I2"
      },
      "cell_type": "code",
      "source": [
        "#-------------- \n",
        "# Random Forest \n",
        "#--------------\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators=10)\n",
        "classifier.fit( X_train, y_train )\n",
        "y_pred = classifier.predict( X_test )\n",
        "\n",
        "cm = confusion_matrix( y_test, y_pred )\n",
        "print(\"Accuracy on Test Set for RandomForest = %.2f\" % ((cm[0,0] + cm[1,1] )/len(X_test)))\n",
        "scoresRF = cross_val_score( classifier, X_train, y_train, cv=10)\n",
        "print(\"Mean RandomForest CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresRF.mean(), scoresRF.std() ))\n",
        "\n",
        "#-------------- \n",
        "# kernel SVM \n",
        "#--------------\n",
        "from sklearn.svm import SVC\n",
        "classifier1 = SVC(kernel=\"rbf\")\n",
        "classifier1.fit( X_train, y_train )\n",
        "y_pred = classifier1.predict( X_test )\n",
        "\n",
        "cm = confusion_matrix( y_test, y_pred )\n",
        "print(\"Accuracy on Test Set for kernel-SVM = %.2f\" % ((cm[0,0] + cm[1,1] )/len(X_test)))\n",
        "scoresSVC = cross_val_score( classifier1, X_train, y_train, cv=10)\n",
        "print(\"Mean kernel-SVM CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresSVC.mean(), scoresSVC.std() ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "c3b0792875551165d563116b0e12bc15bf041e65",
        "id": "2qOrWNjxa9I3"
      },
      "cell_type": "markdown",
      "source": [
        "We'll check some of the other classifiers - but we  don't expect they will do better "
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "21c7b8f059735217a0d451caac6f668715a6000a",
        "id": "zBPJ1vUXa9I4"
      },
      "cell_type": "code",
      "source": [
        "#-------------- \n",
        "# Logistic Regression \n",
        "#--------------\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "classifier2 = LogisticRegression()\n",
        "classifier2.fit( X_train, y_train )\n",
        "y_pred = classifier2.predict( X_test )\n",
        "\n",
        "cm = confusion_matrix( y_test, y_pred )\n",
        "print(\"Accuracy on Test Set for LogReg = %.2f\" % ((cm[0,0] + cm[1,1] )/len(X_test)))\n",
        "scoresLR = cross_val_score( classifier2, X_train, y_train, cv=10)\n",
        "print(\"Mean LogReg CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresLR.mean(), scoresLR.std() ))\n",
        "\n",
        "#-------------- \n",
        "# Naive Bayes \n",
        "#--------------\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "classifier3 = GaussianNB()\n",
        "classifier3.fit( X_train, y_train )\n",
        "y_pred = classifier3.predict( X_test )\n",
        "cm = confusion_matrix( y_test, y_pred )\n",
        "print(\"Accuracy on Test Set for NBClassifier = %.2f\" % ((cm[0,0] + cm[1,1] )/len(X_test)))\n",
        "scoresNB = cross_val_score( classifier3, X_train, y_train, cv=10)\n",
        "print(\"Mean NaiveBayes CrossVal Accuracy on Train Set %.2f, with std=%.2f\" % (scoresNB.mean(), scoresNB.std() ))\n",
        "\n",
        "#-------------- \n",
        "# K-NEIGHBOURS \n",
        "#--------------\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "classifier4 = KNeighborsClassifier(n_neighbors=5)\n",
        "classifier4.fit( X_train, y_train )\n",
        "y_pred = classifier4.predict( X_test )\n",
        "cm = confusion_matrix( y_test, y_pred )\n",
        "print(\"Accuracy on Test Set for KNeighborsClassifier = %.2f\" % ((cm[0,0] + cm[1,1] )/len(X_test)))\n",
        "scoresKN = cross_val_score( classifier3, X_train, y_train, cv=10)\n",
        "print(\"Mean KN CrossVal Accuracy on Train Set Set %.2f, with std=%.2f\" % (scoresKN.mean(), scoresKN.std() ))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "a1fe0a1044b7c27a17f00848b83b2b206fb1be5f",
        "id": "qqDPff4Ua9I5"
      },
      "cell_type": "markdown",
      "source": [
        "**Conclusion:**\n",
        "Using a kernel-SVM classifier, we can predict with ~82% accuracy, whether a customer is likely to default next month. \n",
        "\n",
        "The strongest predictors of default are the PAY_X (ie the repayment status in previous months), the LIMIT_BAL & the PAY_AMTX (amount paid in previous months). \n",
        "\n",
        "Demographics: we see that being Female, More educated, Single and between 30-40years old means a customer is more likely to make payments on time.\n"
      ]
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "collapsed": true,
        "trusted": true,
        "id": "7wjVzOpua9I6"
      },
      "cell_type": "code",
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}